{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devashish-23/deep-learning-project-/blob/main/BFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# TCS.NS Forecasting — RF | XGB | ARIMA | LSTM\n",
        "# Target = next-day log-return; Evaluate/Forecast in PRICE space\n",
        "# Adds RSI, MACD, BBWidth, Volatility, ATR, Stoch, OBV, EMAs\n",
        "# + Percentage error summary (MAPE, MdAPE, P95 APE, Direction Accuracy)\n",
        "# ================================================================\n",
        "import re, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Config\n",
        "# ---------------------------\n",
        "FILE_PATH = \"/content/TCS_NS.csv\"\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load & Clean\n",
        "# ---------------------------\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "df.columns = [c.strip().lower() for c in df.columns]\n",
        "\n",
        "# parse date\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df = df.dropna(subset=['date']).sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# numeric parser\n",
        "def parse_number(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    if isinstance(x, (int, float, np.number)): return float(x)\n",
        "    s = str(x).strip().replace(',', '').replace('₹','')\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "num_cols = [c for c in df.columns if c != 'date']\n",
        "for c in num_cols:\n",
        "    df[c] = df[c].apply(parse_number)\n",
        "\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "print(\"Cleaned data shape:\", df.shape)\n",
        "print(\"Date range:\", df['date'].min().date(), \"→\", df['date'].max().date())\n",
        "\n",
        "# convenience\n",
        "CLOSE = 'close_tcs.ns'\n",
        "OPEN  = 'open_tcs.ns'\n",
        "HIGH  = 'high_tcs.ns'\n",
        "LOW   = 'low_tcs.ns'\n",
        "VOL   = 'volume_tcs.ns'\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Core transforms: log-returns\n",
        "# ---------------------------\n",
        "df['close_lag1'] = df[CLOSE].shift(1)\n",
        "df['log_ret'] = np.log(df[CLOSE] / df['close_lag1'])\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Technical Indicators (no external libs)\n",
        "# ---------------------------\n",
        "\n",
        "# % changes\n",
        "for col in [OPEN, HIGH, LOW, CLOSE, VOL]:\n",
        "    df[f'{col}_pct'] = df[col].pct_change()\n",
        "\n",
        "# Ratios\n",
        "df['close_over_open'] = df[CLOSE] / df[OPEN]\n",
        "df['high_over_low']   = df[HIGH]  / df[LOW]\n",
        "\n",
        "# EMAs (for MACD and as features)\n",
        "def ema(series, span):\n",
        "    return series.ewm(span=span, adjust=False).mean()\n",
        "\n",
        "df['ema_5']  = ema(df[CLOSE], 5)\n",
        "df['ema_10'] = ema(df[CLOSE], 10)\n",
        "df['ema_20'] = ema(df[CLOSE], 20)\n",
        "df['ema_50'] = ema(df[CLOSE], 50)\n",
        "df['ema_200']= ema(df[CLOSE], 200)\n",
        "\n",
        "# MACD(12,26,9)\n",
        "df['ema_12'] = ema(df[CLOSE], 12)\n",
        "df['ema_26'] = ema(df[CLOSE], 26)\n",
        "df['macd']   = df['ema_12'] - df['ema_26']\n",
        "df['macd_sig']= ema(df['macd'], 9)\n",
        "df['macd_hist']= df['macd'] - df['macd_sig']\n",
        "\n",
        "# RSI(14)\n",
        "def rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()\n",
        "    avg_loss = loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()\n",
        "    rs = avg_gain / (avg_loss.replace(0, np.nan))\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "df['rsi_14'] = rsi(df[CLOSE], 14)\n",
        "\n",
        "# Bollinger Bands (20, 2σ) + Width\n",
        "mid = df[CLOSE].rolling(20).mean()\n",
        "std = df[CLOSE].rolling(20).std()\n",
        "upper = mid + 2*std\n",
        "lower = mid - 2*std\n",
        "df['bb_width'] = (upper - lower) / mid\n",
        "\n",
        "# Rolling volatility of returns\n",
        "for w in [5,10,20]:\n",
        "    df[f'vol_{w}'] = df['log_ret'].rolling(w).std()\n",
        "\n",
        "# ATR(14)\n",
        "tr1 = df[HIGH] - df[LOW]\n",
        "tr2 = (df[HIGH] - df[CLOSE].shift(1)).abs()\n",
        "tr3 = (df[LOW]  - df[CLOSE].shift(1)).abs()\n",
        "tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "df['atr_14'] = tr.rolling(14).mean()\n",
        "\n",
        "# Stochastic Oscillator %K(14) and %D(3)\n",
        "low14  = df[LOW].rolling(14).min()\n",
        "high14 = df[HIGH].rolling(14).max()\n",
        "df['stoch_k'] = 100 * (df[CLOSE] - low14) / (high14 - low14)\n",
        "df['stoch_d'] = df['stoch_k'].rolling(3).mean()\n",
        "\n",
        "# OBV\n",
        "delta_close = df[CLOSE].diff()\n",
        "direction = np.sign(delta_close).fillna(0)\n",
        "df['obv'] = (direction * df[VOL]).cumsum()\n",
        "\n",
        "# MAs (already present) + slopes & spreads\n",
        "for span in [5,10,20,50,200]:\n",
        "    ma_col = f'ma_{span}'\n",
        "    if ma_col in df.columns:\n",
        "        df[f'{ma_col}_slope'] = df[ma_col] - df[ma_col].shift(1)\n",
        "\n",
        "if all(c in df.columns for c in ['ma_5','ma_10','ma_20','ma_50','ma_200']):\n",
        "    df['ma5_10_spread']  = df['ma_5']  - df['ma_10']\n",
        "    df['ma10_20_spread'] = df['ma_10'] - df['ma_20']\n",
        "    df['ma20_50_spread'] = df['ma_20'] - df['ma_50']\n",
        "    df['ma50_200_spread']= df['ma_50'] - df['ma_200']\n",
        "\n",
        "# Lagged returns (t-1..t-10)\n",
        "for k in range(1, 11):\n",
        "    df[f'log_ret_lag{k}'] = df['log_ret'].shift(k)\n",
        "\n",
        "# Label: next-day return\n",
        "df['y_next_ret'] = df['log_ret'].shift(-1)\n",
        "\n",
        "# Drop NaNs created by indicators/rollings\n",
        "df_feat = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Features & Labels (clean inf/NaN)\n",
        "# ---------------------------\n",
        "feat_cols = []\n",
        "\n",
        "# Price dynamics\n",
        "feat_cols += [f'{OPEN}_pct', f'{HIGH}_pct', f'{LOW}_pct', f'{CLOSE}_pct', f'{VOL}_pct',\n",
        "              'close_over_open','high_over_low']\n",
        "\n",
        "# EMAs\n",
        "feat_cols += ['ema_5','ema_10','ema_20','ema_50','ema_200']\n",
        "\n",
        "# MACD suite\n",
        "feat_cols += ['macd','macd_sig','macd_hist']\n",
        "\n",
        "# RSI, BBWidth, Volatility, ATR, Stoch, OBV\n",
        "feat_cols += ['rsi_14','bb_width','vol_5','vol_10','vol_20','atr_14','stoch_k','stoch_d','obv']\n",
        "\n",
        "# MAs (if present) and their slopes / spreads\n",
        "for span in [5,10,20,50,200]:\n",
        "    if f'ma_{span}' in df_feat.columns: feat_cols.append(f'ma_{span}')\n",
        "    if f'ma_{span}_slope' in df_feat.columns: feat_cols.append(f'ma_{span}_slope')\n",
        "for c in ['ma5_10_spread','ma10_20_spread','ma20_50_spread','ma50_200_spread']:\n",
        "    if c in df_feat.columns: feat_cols.append(c)\n",
        "\n",
        "# Lagged returns\n",
        "feat_cols += [f'log_ret_lag{k}' for k in range(1,11)]\n",
        "\n",
        "X = df_feat[feat_cols].copy()\n",
        "y = df_feat['y_next_ret'].copy()\n",
        "\n",
        "# Clean ∞/NaN\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "y = y.replace([np.inf, -np.inf], np.nan)\n",
        "valid_mask = X.notna().all(axis=1) & y.notna()\n",
        "X = X[valid_mask].reset_index(drop=True)\n",
        "y = y[valid_mask].reset_index(drop=True)\n",
        "df_feat = df_feat.loc[valid_mask].reset_index(drop=True)\n",
        "\n",
        "# Split (time-aware)\n",
        "split_idx = int(len(df_feat)*0.8)\n",
        "train_idx = np.arange(0, split_idx)\n",
        "test_idx  = np.arange(split_idx, len(df_feat))\n",
        "\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "# Evaluation in PRICE space\n",
        "close_for_test_base = df_feat[CLOSE].iloc[test_idx - 1].reset_index(drop=True)\n",
        "actual_close_tplus1 = df_feat[CLOSE].iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "def price_metrics_from_returns(close_t, pred_ret, actual_t1):\n",
        "    pred_price = close_t.values * np.exp(pred_ret)\n",
        "    rmse = math.sqrt(mean_squared_error(actual_t1.values, pred_price))\n",
        "    mape = mean_absolute_percentage_error(actual_t1.values, pred_price)*100\n",
        "    acc  = 100 - mape\n",
        "    return rmse, mape, acc, pred_price\n",
        "\n",
        "results = {}\n",
        "pred_price_traces = {}  # store predicted price series on test set\n",
        "\n",
        "# ---------------------------\n",
        "# 5) RandomForest (slightly regularized)\n",
        "# ---------------------------\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=700, max_depth=None, min_samples_leaf=5,\n",
        "    random_state=SEED, n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "rf_ret_test = rf.predict(X_test)\n",
        "rmse, mape, acc, rf_pred_prices = price_metrics_from_returns(close_for_test_base, rf_ret_test, actual_close_tplus1)\n",
        "results['RandomForest'] = (rmse, mape, acc)\n",
        "pred_price_traces['RandomForest'] = rf_pred_prices\n",
        "\n",
        "# ---------------------------\n",
        "# 6) XGBoost (tuned a bit)\n",
        "# ---------------------------\n",
        "xgbr = xgb.XGBRegressor(\n",
        "    n_estimators=900, learning_rate=0.03, max_depth=6,\n",
        "    subsample=0.9, colsample_bytree=0.9,\n",
        "    reg_lambda=2.0, reg_alpha=0.0,\n",
        "    random_state=SEED\n",
        ")\n",
        "xgbr.fit(X_train, y_train)\n",
        "xgb_ret_test = xgbr.predict(X_test)\n",
        "rmse, mape, acc, xgb_pred_prices = price_metrics_from_returns(close_for_test_base, xgb_ret_test, actual_close_tplus1)\n",
        "results['XGBoost'] = (rmse, mape, acc)\n",
        "pred_price_traces['XGBoost'] = xgb_pred_prices\n",
        "\n",
        "# ---------------------------\n",
        "# 7) ARIMA on returns (short-memory AR)\n",
        "# ---------------------------\n",
        "ret_series = df_feat['log_ret']\n",
        "ret_train, ret_test = ret_series.iloc[train_idx], ret_series.iloc[test_idx]\n",
        "# modest AR order\n",
        "arima = ARIMA(ret_train, order=(5,0,0))\n",
        "arima_fit = arima.fit()\n",
        "arima_ret_test = arima_fit.forecast(len(ret_test))\n",
        "rmse, mape, acc, arima_pred_prices = price_metrics_from_returns(close_for_test_base, arima_ret_test, actual_close_tplus1)\n",
        "results['ARIMA'] = (rmse, mape, acc)\n",
        "pred_price_traces['ARIMA'] = arima_pred_prices\n",
        "\n",
        "# ---------------------------\n",
        "# 8) LSTM on returns (sequence)\n",
        "# ---------------------------\n",
        "scaler = MinMaxScaler((0,1))\n",
        "ret_all = ret_series.values.reshape(-1,1)\n",
        "ret_scaled = scaler.fit_transform(ret_all)\n",
        "\n",
        "def seq_xy(data, n_steps=60):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(n_steps, len(data)):\n",
        "        Xs.append(data[i-n_steps:i, 0])\n",
        "        ys.append(data[i, 0])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "N_STEPS = 60\n",
        "X_all, y_all = seq_xy(ret_scaled, N_STEPS)\n",
        "split_pos = int(len(X_all)*0.8)\n",
        "Xtr, Xte = X_all[:split_pos], X_all[split_pos:]\n",
        "ytr, yte = y_all[:split_pos], y_all[split_pos:]\n",
        "\n",
        "Xtr = Xtr.reshape((Xtr.shape[0], N_STEPS, 1))\n",
        "Xte = Xte.reshape((Xte.shape[0], N_STEPS, 1))\n",
        "\n",
        "lstm = Sequential([\n",
        "    Input(shape=(N_STEPS,1)),\n",
        "    LSTM(96, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(96),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse')\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=1e-5, verbose=1)\n",
        "]\n",
        "lstm.fit(Xtr, ytr, validation_split=0.1, epochs=100, batch_size=32, verbose=0, callbacks=callbacks)\n",
        "\n",
        "lstm_ret_pred_scaled = lstm.predict(Xte, verbose=0)\n",
        "lstm_ret_pred = scaler.inverse_transform(lstm_ret_pred_scaled).ravel()\n",
        "\n",
        "# Align LSTM price evaluation\n",
        "abs_start = N_STEPS + split_pos\n",
        "close_bases_lstm = df_feat[CLOSE].iloc[abs_start-1 : abs_start-1 + len(lstm_ret_pred)].reset_index(drop=True)\n",
        "actuals_lstm     = df_feat[CLOSE].iloc[abs_start   : abs_start   + len(lstm_ret_pred)].reset_index(drop=True)\n",
        "\n",
        "rmse, mape, acc, lstm_pred_prices = price_metrics_from_returns(close_bases_lstm, lstm_ret_pred, actuals_lstm)\n",
        "results['LSTM'] = (rmse, mape, acc)\n",
        "pred_price_traces['LSTM'] = lstm_pred_prices\n",
        "\n",
        "# ---------------------------\n",
        "# 9) Report metrics\n",
        "# ---------------------------\n",
        "print(\"\\n=== Model Comparison (Test, Price space) ===\")\n",
        "for k,(rmse,mape,acc) in results.items():\n",
        "    print(f\"{k:12s} | RMSE={rmse:.2f} | MAPE={mape:.2f}% | Accuracy≈{acc:.2f}%\")\n",
        "\n",
        "# ---------------------------\n",
        "# 10) Multi-horizon forecasts (t+1, t+5, t+20)\n",
        "# ---------------------------\n",
        "last_date = df['date'].iloc[-1]\n",
        "last_close = df[CLOSE].iloc[-1]\n",
        "print(\"\\nLast known trading date:\", last_date.date(), \"Close:\", last_close)\n",
        "\n",
        "def next_business_dates(start_date, steps_list):\n",
        "    out = {}\n",
        "    for s in steps_list:\n",
        "        out[s] = np.busday_offset(start_date.date(), s, weekmask='1111100')\n",
        "    return {s: pd.Timestamp(d) for s,d in out.items()}\n",
        "\n",
        "target_steps = [1,5,20]\n",
        "target_dates = next_business_dates(last_date, target_steps)\n",
        "\n",
        "# Helper to roll forward returns for RF/XGB (freeze non-lag features; update lagged returns)\n",
        "lag_keys = [f'log_ret_lag{k}' for k in range(1,11)]\n",
        "def roll_forward_returns(model, base_feat_row, steps):\n",
        "    row = base_feat_row.copy()\n",
        "    preds = []\n",
        "    lag_vals = [row[k] for k in lag_keys]\n",
        "    for _ in range(steps):\n",
        "        pred_ret = model.predict(pd.DataFrame([row.values], columns=feat_cols))[0]\n",
        "        preds.append(pred_ret)\n",
        "        lag_vals = lag_vals[1:] + [pred_ret]\n",
        "        for i,k in enumerate(lag_keys):\n",
        "            row[k] = lag_vals[i]\n",
        "    return np.array(preds)\n",
        "\n",
        "# Build last feature row for RF/XGB\n",
        "last_feat_row = X.iloc[[-1]].copy().iloc[0]\n",
        "\n",
        "# RF forward\n",
        "rf_fwd_rets  = roll_forward_returns(rf, last_feat_row, max(target_steps))\n",
        "rf_prices    = last_close * np.exp(np.cumsum(rf_fwd_rets))\n",
        "# XGB forward\n",
        "xgb_fwd_rets = roll_forward_returns(xgbr, last_feat_row, max(target_steps))\n",
        "xgb_prices   = last_close * np.exp(np.cumsum(xgb_fwd_rets))\n",
        "# ARIMA forward (returns)\n",
        "arima_fwd_rets = arima_fit.forecast(max(target_steps)).values\n",
        "arima_prices   = last_close * np.exp(np.cumsum(arima_fwd_rets))\n",
        "# LSTM forward (returns)\n",
        "ret_series_all = df_feat['log_ret'].values.reshape(-1,1)\n",
        "last_returns_scaled = scaler.transform(ret_series_all[-N_STEPS:]).reshape(1,N_STEPS,1)\n",
        "lstm_fwd_scaled = []\n",
        "seq = last_returns_scaled.copy()\n",
        "for _ in range(max(target_steps)):\n",
        "    nxt = lstm.predict(seq, verbose=0)[0,0]\n",
        "    lstm_fwd_scaled.append(nxt)\n",
        "    seq = np.concatenate([seq[:,1:,:], np.array([[[nxt]]])], axis=1)\n",
        "lstm_fwd_rets = scaler.inverse_transform(np.array(lstm_fwd_scaled).reshape(-1,1)).ravel()\n",
        "lstm_prices   = last_close * np.exp(np.cumsum(lstm_fwd_rets))\n",
        "\n",
        "def step_pick(price_path, steps):\n",
        "    return {s: float(price_path[s-1]) for s in steps}\n",
        "\n",
        "future_preds = {\n",
        "    'RandomForest': step_pick(rf_prices,  target_steps),\n",
        "    'XGBoost'     : step_pick(xgb_prices, target_steps),\n",
        "    'ARIMA'       : step_pick(arima_prices, target_steps),\n",
        "    'LSTM'        : step_pick(lstm_prices, target_steps),\n",
        "}\n",
        "\n",
        "print(\"\\n=== Future Predictions (Price) ===\")\n",
        "for model, vals in future_preds.items():\n",
        "    print(f\"{model:12s} | {target_dates[1].date()}: {vals[1]:.2f} | {target_dates[5].date()}: {vals[5]:.2f} | {target_dates[20].date()}: {vals[20]:.2f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 11) Last-10-Days Actual vs Predicted tables (aligned)\n",
        "# ---------------------------\n",
        "def tail_compare(dates, actual, pred, n=10):\n",
        "    d = pd.DataFrame({\n",
        "        'Date': dates[-n:].dt.date,\n",
        "        'Actual_Close': np.array(actual)[-n:],\n",
        "        'Pred_Close'  : np.array(pred)[-n:]\n",
        "    })\n",
        "    d['Abs_Err']   = (d['Pred_Close'] - d['Actual_Close']).abs()\n",
        "    d['Pct_Err_%'] = 100 * d['Abs_Err'] / d['Actual_Close']\n",
        "    return d\n",
        "\n",
        "test_dates_for_price = df_feat['date'].iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "rf_tail    = tail_compare(test_dates_for_price, actual_close_tplus1, pred_price_traces['RandomForest'])\n",
        "xgb_tail   = tail_compare(test_dates_for_price, actual_close_tplus1, pred_price_traces['XGBoost'])\n",
        "arima_tail = tail_compare(test_dates_for_price, actual_close_tplus1, pred_price_traces['ARIMA'])\n",
        "\n",
        "lstm_dates   = df_feat['date'].iloc[abs_start : abs_start + len(pred_price_traces['LSTM'])].reset_index(drop=True)\n",
        "lstm_actuals = df_feat[CLOSE].iloc[abs_start : abs_start + len(pred_price_traces['LSTM'])].reset_index(drop=True)\n",
        "lstm_tail    = tail_compare(lstm_dates, lstm_actuals, pred_price_traces['LSTM'])\n",
        "\n",
        "print(\"\\n--- Last 10 Days: RandomForest ---\\n\", rf_tail.to_string(index=False))\n",
        "print(\"\\n--- Last 10 Days: XGBoost ---\\n\", xgb_tail.to_string(index=False))\n",
        "print(\"\\n--- Last 10 Days: ARIMA ---\\n\", arima_tail.to_string(index=False))\n",
        "print(\"\\n--- Last 10 Days: LSTM ---\\n\", lstm_tail.to_string(index=False))\n",
        "\n",
        "# ---------------------------\n",
        "# 12) Percentage error summary (test set)\n",
        "#     - MdAPE (median absolute % error)\n",
        "#     - P95 APE (95th percentile of absolute % error)\n",
        "#     - Direction accuracy (correct sign of next-day return)\n",
        "# ---------------------------\n",
        "summary_rows = []\n",
        "\n",
        "def ape_stats(actual_prices, pred_prices):\n",
        "    ape = 100 * np.abs(pred_prices - actual_prices) / actual_prices\n",
        "    mdape = np.median(ape)\n",
        "    p95 = np.percentile(ape, 95)\n",
        "    return mdape, p95, ape\n",
        "\n",
        "# RF/XGB/ARIMA share the same test alignment\n",
        "models_order = ['RandomForest','XGBoost','ARIMA']\n",
        "for m in models_order:\n",
        "    mdape, p95, ape_vec = ape_stats(actual_close_tplus1.values, pred_price_traces[m])\n",
        "    summary_rows.append([m, float(mdape), float(p95)])\n",
        "\n",
        "# LSTM has its own alignment\n",
        "mdape, p95, ape_vec_lstm = ape_stats(lstm_actuals.values, pred_price_traces['LSTM'])\n",
        "summary_rows.append(['LSTM', float(mdape), float(p95)])\n",
        "\n",
        "# Direction accuracy: compare sign of next-day return between actual and predicted (price-based)\n",
        "def direction_accuracy(actual_prices, pred_prices):\n",
        "    act_ret = np.sign(np.diff(actual_prices))\n",
        "    prd_ret = np.sign(np.diff(pred_prices))\n",
        "    n = min(len(act_ret), len(prd_ret))\n",
        "    if n == 0: return np.nan\n",
        "    return 100.0 * (act_ret[:n] == prd_ret[:n]).mean()\n",
        "\n",
        "dir_rows = []\n",
        "for m in models_order:\n",
        "    da = direction_accuracy(actual_close_tplus1.values, pred_price_traces[m])\n",
        "    dir_rows.append([m, float(da)])\n",
        "da_lstm = direction_accuracy(lstm_actuals.values, pred_price_traces['LSTM'])\n",
        "dir_rows.append(['LSTM', float(da_lstm)])\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows, columns=['Model','MdAPE_%','P95_APE_%'])\n",
        "dir_df = pd.DataFrame(dir_rows, columns=['Model','Direction_Accuracy_%'])\n",
        "\n",
        "print(\"\\n=== Percentage Error Summary (Test) ===\")\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"\\n=== Direction Accuracy (Test) ===\")\n",
        "print(dir_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "fD70CmAw016R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}